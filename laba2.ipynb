{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a071587d-f98c-4a2a-bdc5-383d4c400bcc",
   "metadata": {},
   "source": [
    "# 1-ая часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2a7f73-0f7d-495e-9ba8-30c536340d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f3b0cf-ba47-4dac-a0f8-0010a7cfff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------+------------+--------+---------+-----------+----------+-----+\n",
      "|GAME|             Opening|Result| Termination|WhiteElo|Game_type|Total_moves|Game_flips|label|\n",
      "+----+--------------------+------+------------+--------+---------+-----------+----------+-----+\n",
      "|  11|        Bird Opening|   0-1|Time forfeit|    1180|    Blitz|         66|         8|    0|\n",
      "|  14|        Réti Opening|   0-1|      Normal|    1381|    Blitz|         64|         6|    0|\n",
      "|  29|    Philidor Defense|   0-1|Time forfeit|    1485|    Blitz|         70|         5|    1|\n",
      "|  40|Sicilian Defense:...|   0-1|      Normal|    2040|    Blitz|         86|         8|    1|\n",
      "|  55|    Alekhine Defense|   1-0|      Normal|    2163|    Rapid|         71|         2|    1|\n",
      "|  56|Nimzo-Indian Defe...|   0-1|      Normal|    2062|    Rapid|         73|         6|    1|\n",
      "|  70|   Queen's Pawn Game|   1-0|      Normal|    1651|   Bullet|         39|         3|    1|\n",
      "| 162|Four Knights Game...|   1-0|      Normal|    1088|    Blitz|         69|        13|    0|\n",
      "| 196|King's Indian Def...|   0-1|Time forfeit|    1559|    Rapid|         28|         3|    0|\n",
      "| 239|French Defense: K...|   0-1|      Normal|    1648|    Blitz|         52|         1|    1|\n",
      "+----+--------------------+------+------------+--------+---------+-----------+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename_data = 'chess.csv'\n",
    "csv = spark.read.csv(filename_data, inferSchema=True, header=True)\n",
    "csv = csv.drop(csv._c0).withColumn('label', when(col('BlackElo') >= 1592, 1).otherwise(0))\n",
    "csv.drop(csv['BlackElo']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b68682a7-6d46-4fbd-bcc7-37ea78303c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 2407659  Testing Rows: 1031792\n"
     ]
    }
   ],
   "source": [
    "splits = csv.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\n",
    "train_rows = train.count()\n",
    "test_rows = test.count()\n",
    "print(\"Training Rows:\", train_rows, \" Testing Rows:\", test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a55c9a4-1ede-4b9a-9047-4215dff49a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "strIdx = StringIndexer(inputCols = ['Game_type'], \n",
    "                       outputCols = ['Game_typeIdx'], \n",
    "                       handleInvalid = \"keep\")\n",
    "catVect = VectorAssembler(inputCols = ['Game_typeIdx'], outputCol=\"catFeatures\")\n",
    "catIdx = VectorIndexer(inputCol = catVect.getOutputCol(), outputCol = \"idxCatFeatures\")\n",
    "numVect = VectorAssembler(inputCols = ['Total_moves', 'Game_flips', 'WhiteElo'], outputCol=\"numFeatures\")\n",
    "minMax = MinMaxScaler(inputCol = numVect.getOutputCol(), outputCol=\"normFeatures\")\n",
    "featVect = VectorAssembler(inputCols=[\"idxCatFeatures\", \"normFeatures\"], outputCol=\"features\")\n",
    "lr = LogisticRegression(labelCol=\"label\", \n",
    "                        featuresCol=\"features\", \n",
    "                        maxIter=30,\n",
    "                        regParam=0.3)\n",
    "pipeline = Pipeline(stages=[strIdx, catVect, catIdx, numVect, minMax, featVect, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ffd6d0-f45e-4a74-bea0-da6f1b72bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2610486f-fae7-48f7-b293-36cb8d5c3c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+\n",
      "|            features|prediction|trueLabel|\n",
      "+--------------------+----------+---------+\n",
      "|[0.0,0.4491525423...|       1.0|        1|\n",
      "|[0.0,0.7203389830...|       0.0|        0|\n",
      "|[0.0,0.6271186440...|       1.0|        1|\n",
      "|[2.0,0.0508474576...|       1.0|        0|\n",
      "|[0.0,0.5677966101...|       1.0|        1|\n",
      "|[2.0,0.8050847457...|       1.0|        1|\n",
      "|[0.0,0.3220338983...|       1.0|        1|\n",
      "|[0.0,0.6864406779...|       1.0|        1|\n",
      "|[2.0,0.7881355932...|       1.0|        1|\n",
      "|[0.0,0.5169491525...|       0.0|        0|\n",
      "|[0.0,0.6016949152...|       0.0|        0|\n",
      "|[0.0,0.6271186440...|       1.0|        1|\n",
      "|[0.0,0.2966101694...|       1.0|        1|\n",
      "|[0.0,0.5593220338...|       1.0|        1|\n",
      "|[2.0,0.6186440677...|       0.0|        0|\n",
      "|[2.0,0.3728813559...|       0.0|        0|\n",
      "|[1.0,0.4661016949...|       1.0|        1|\n",
      "|[0.0,0.6525423728...|       1.0|        1|\n",
      "|[1.0,0.3644067796...|       0.0|        0|\n",
      "|[1.0,0.3983050847...|       0.0|        0|\n",
      "+--------------------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_df = pipelineModel.transform(test)\n",
    "pred_df.select(\"features\", \"prediction\", \"trueLabel\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1e16b96-d652-49ff-8f10-a433ac421a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[GAME: int, BlackElo: int, Opening: string, Result: string, Termination: string, WhiteElo: int, Game_type: string, Total_moves: int, Game_flips: int, trueLabel: int, Game_typeIdx: double, catFeatures: vector, idxCatFeatures: vector, numFeatures: vector, normFeatures: vector, features: vector, rawPrediction: vector, probability: vector, prediction: double]\n",
      "+---------+------------------+\n",
      "|   metric|             value|\n",
      "+---------+------------------+\n",
      "|       TP|          449408.0|\n",
      "|       FP|           41887.0|\n",
      "|       TN|          482153.0|\n",
      "|       FN|           58344.0|\n",
      "|Precision|0.9147416521641784|\n",
      "|   Recall|0.8850935102175865|\n",
      "|       F1|0.8996733887394688|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pred_df)\n",
    "tp = float(pred_df.filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
    "fp = float(pred_df.filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
    "tn = float(pred_df.filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
    "fn = float(pred_df.filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
    "pr = tp / (tp + fp)\n",
    "re = tp / (tp + fn)\n",
    "metrics = spark.createDataFrame([\n",
    " (\"TP\", tp),\n",
    " (\"FP\", fp),\n",
    " (\"TN\", tn),\n",
    " (\"FN\", fn),\n",
    " (\"Precision\", pr),\n",
    " (\"Recall\", re),\n",
    " (\"F1\", 2*pr*re/(re+pr))],[\"metric\", \"value\"])\n",
    "metrics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b526a9c-7b8c-4148-970e-ff279e53adbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUR =  0.9524713926047002\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "aur = evaluator.evaluate(pred_df)\n",
    "print (\"AUR = \", aur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d66785-2501-408e-b9e3-38ed38202573",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder().\\\n",
    "    addGrid(lr.maxIter, [30, 40, 60]).\\\n",
    "    addGrid(lr.regParam, [0.6, 0.8, 0.9]).build()\n",
    "cv = CrossValidator(estimator=pipeline, evaluator=BinaryClassificationEvaluator(metricName='areaUnderPR'), estimatorParamMaps=paramGrid, \n",
    "                    numFolds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8defc0b-4494-4b96-a44a-b43ffc63659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f2e349-7735-4cb5-b99f-933c2084614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "newPrediction = cv_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb80b2e3-58e8-4e1b-9064-aefcd9ca49a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|   metric|             value|\n",
      "+---------+------------------+\n",
      "|       TP|          442338.0|\n",
      "|       FP|           40344.0|\n",
      "|       TN|          483696.0|\n",
      "|       FN|           65414.0|\n",
      "|Precision|0.9164170199013015|\n",
      "|   Recall|0.8711693897808379|\n",
      "|       F1|0.8932205477598709|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recalculate confusion matrix\n",
    "tp2 = float(newPrediction.filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
    "fp2 = float(newPrediction.filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
    "tn2 = float(newPrediction.filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
    "fn2 = float(newPrediction.filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
    "pr2 = tp2 / (tp2 + fp2)\n",
    "re2 = tp2 / (tp2 + fn2)\n",
    "metrics2 = spark.createDataFrame([\n",
    " (\"TP\", tp2),\n",
    " (\"FP\", fp2),\n",
    " (\"TN\", tn2),\n",
    " (\"FN\", fn2),\n",
    " (\"Precision\", pr2),\n",
    " (\"Recall\", re2),\n",
    " (\"F1\", 2*pr2*re2/(re2+pr2))],[\"metric\", \"value\"])\n",
    "metrics2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f4bb2f1-e7eb-465b-b626-b0a734b6aadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUR2 =  0.897091450099945\n"
     ]
    }
   ],
   "source": [
    "# Recalculate the Area Under ROC\n",
    "evaluator2 = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "aur2 = evaluator2.evaluate(newPrediction)\n",
    "print( \"AUR2 = \", aur2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f8f73b-8f79-4787-a502-d8d45888c4e7",
   "metadata": {},
   "source": [
    "# 2-ая часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51abfb72-357d-4141-87c1-0c511e89d06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+--------------------+------+------------+--------+---------+-----------+----------+\n",
      "|_c0|GAME|BlackElo|             Opening|Result| Termination|WhiteElo|Game_type|Total_moves|Game_flips|\n",
      "+---+----+--------+--------------------+------+------------+--------+---------+-----------+----------+\n",
      "|  0|  11|    1143|        Bird Opening|   0-1|Time forfeit|    1180|    Blitz|         66|         8|\n",
      "|  1|  14|    1504|        Réti Opening|   0-1|      Normal|    1381|    Blitz|         64|         6|\n",
      "|  2|  29|    1933|    Philidor Defense|   0-1|Time forfeit|    1485|    Blitz|         70|         5|\n",
      "|  3|  40|    1710|Sicilian Defense:...|   0-1|      Normal|    2040|    Blitz|         86|         8|\n",
      "|  4|  55|    1598|    Alekhine Defense|   1-0|      Normal|    2163|    Rapid|         71|         2|\n",
      "|  5|  56|    2207|Nimzo-Indian Defe...|   0-1|      Normal|    2062|    Rapid|         73|         6|\n",
      "|  6|  70|    1632|   Queen's Pawn Game|   1-0|      Normal|    1651|   Bullet|         39|         3|\n",
      "|  7| 162|     942|Four Knights Game...|   1-0|      Normal|    1088|    Blitz|         69|        13|\n",
      "|  8| 196|    1500|King's Indian Def...|   0-1|Time forfeit|    1559|    Rapid|         28|         3|\n",
      "|  9| 239|    1728|French Defense: K...|   0-1|      Normal|    1648|    Blitz|         52|         1|\n",
      "+---+----+--------+--------------------+------+------------+--------+---------+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv = spark.read.csv(filename_data, inferSchema=True, header=True)\n",
    "# csv = csv.withColumn('Rating', csv.Rating.cast(IntegerType()))\n",
    "csv.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b11babf4-e8c7-467d-9f64-3c845763fca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 2408467  Testing Rows: 1030984\n"
     ]
    }
   ],
   "source": [
    "splits = csv.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1].withColumnRenamed(\"BlackElo\", \"trueBlackElo\")\n",
    "train_rows = train.count()\n",
    "test_rows = test.count()\n",
    "print(\"Training Rows:\", train_rows, \" Testing Rows:\", test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02d09abc-6db6-460f-9fb5-082fc0556159",
   "metadata": {},
   "outputs": [],
   "source": [
    "strIdx = StringIndexer(inputCols = ['Game_type'], \n",
    "                       outputCols = ['Game_typeIdx'], \n",
    "                       handleInvalid = \"keep\")\n",
    "catVect = VectorAssembler(inputCols = ['Game_typeIdx'], outputCol=\"catFeatures\")\n",
    "catIdx = VectorIndexer(inputCol = catVect.getOutputCol(), outputCol = \"idxCatFeatures\")\n",
    "numVect = VectorAssembler(inputCols = ['WhiteElo', 'Total_moves', 'Game_flips'], outputCol=\"numFeatures\")\n",
    "minMax = MinMaxScaler(inputCol = numVect.getOutputCol(), outputCol=\"normFeatures\")\n",
    "featVect = VectorAssembler(inputCols=[\"idxCatFeatures\", \"normFeatures\"], outputCol=\"features\")\n",
    "rfr = RandomForestRegressor(featuresCol = 'features', \n",
    "                      labelCol='BlackElo',\n",
    "                      numTrees = 10,\n",
    "                      maxDepth=2,\n",
    "                      maxBins = 2207)\n",
    "pipeline = Pipeline(stages=[strIdx, catVect, catIdx, numVect, minMax, featVect, rfr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "547e6eab-19ae-4fa6-93dc-b60963093053",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "795b6b82-36a6-49b9-b5b5-cb567544f3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------+\n",
      "|            features|        prediction|trueBlackElo|\n",
      "+--------------------+------------------+------------+\n",
      "|[0.0,0.3903826266...|1434.1574524473335|        1504|\n",
      "|[0.0,0.4441571871...|1500.2725358503899|        1933|\n",
      "|[1.0,0.7425025853...|1839.8695592496101|        2207|\n",
      "|[1.0,0.7492244053...|1839.8695592496101|        2141|\n",
      "|[1.0,0.7052740434...| 1815.445441915403|        1943|\n",
      "|[0.0,0.7042399172...|1824.4574131128186|        2000|\n",
      "|[2.0,0.4053774560...|1404.7691807863669|        1440|\n",
      "|[0.0,0.7068252326...|1824.4574131128186|        2293|\n",
      "|[1.0,0.4519131334...|1430.5314210290076|        1500|\n",
      "|[0.0,0.4788004136...|1430.5314210290076|        1537|\n",
      "|[1.0,0.5816959669...|1755.2972331221458|        1778|\n",
      "|[1.0,0.6964839710...| 1845.515756752596|        1813|\n",
      "|[0.0,0.4544984488...|1422.8458691667147|        1510|\n",
      "|[0.0,0.4979317476...|1581.4058977860816|        1139|\n",
      "|[0.0,0.4519131334...|1422.8458691667147|        1500|\n",
      "|[2.0,0.6122026887...| 1780.499999752022|        1772|\n",
      "|[2.0,0.3448810754...|1465.2716578609475|        1219|\n",
      "|[1.0,0.6732161323...|1839.8695592496101|        1920|\n",
      "|[1.0,0.6168562564...| 1734.425446376178|        1824|\n",
      "|[3.0,0.5175801447...|1755.2972331221458|        1244|\n",
      "+--------------------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_df = pipelineModel.transform(test)\n",
    "pred_df.select(\"features\", \"prediction\", \"trueBlackElo\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9810a6ba-adb5-4618-9ad3-b5f1c635a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "regressionEvaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"trueBlackElo\", metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae380bdb-88b0-4efc-a72c-50e0ac3df819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the random forest regression model is 201.67\n",
      "The MSE for the random forest regression model is 40671.89\n",
      "The R2 for the random forest regression model is 0.64\n",
      "The MAE for the random forest regression model is 149.82\n"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "rmse = regressionEvaluator.evaluate(pred_df)\n",
    "print(f\"The RMSE for the random forest regression model is {rmse:0.2f}\")\n",
    "# MSE\n",
    "mse = regressionEvaluator.setMetricName(\"mse\").evaluate(pred_df)\n",
    "print(f\"The MSE for the random forest regression model is {mse:0.2f}\")\n",
    "# R2\n",
    "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(pred_df)\n",
    "print(f\"The R2 for the random forest regression model is {r2:0.2f}\")\n",
    "# MAE\n",
    "mae = regressionEvaluator.setMetricName(\"mae\").evaluate(pred_df)\n",
    "print(f\"The MAE for the random forest regression model is {mae:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6de8d4cb-21dc-4674-88a2-eb87f595171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParamGridBuilder().\\\n",
    "    addGrid(rfr.numTrees, [10, 15, 20]).\\\n",
    "    addGrid(rfr.maxDepth, [1, 2, 4]).\\\n",
    "    addGrid(rfr.maxBins , [2207, 4414, 8828]).\\\n",
    "    build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "437e2f9f-2cff-475e-84ae-98e8f73e573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=pipeline, \\\n",
    "                    estimatorParamMaps=param_grid, \\\n",
    "                    evaluator=RegressionEvaluator(\n",
    "                                predictionCol=\"prediction\", \\\n",
    "                                labelCol=\"BlackElo\", \\\n",
    "                                metricName=\"rmse\"), \\\n",
    "                    numFolds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b133c954-3fca-4f20-b1a0-6a4a237c9907",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7b8837b-aedb-4a39-a62d-face638ee44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "newPrediction = cv_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6f4e455-52db-4c46-b3d3-1fb58cd367f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the random forest regression model is 106.46\n",
      "The MSE for the random forest regression model is 24713.13\n",
      "The R2 for the random forest regression model is 0.78\n",
      "The MAE for the random forest regression model is 106.46\n"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "rmse = regressionEvaluator.evaluate(newPrediction)\n",
    "print(f\"The RMSE for the random forest regression model is {rmse:0.2f}\")\n",
    "# MSE\n",
    "mse = regressionEvaluator.setMetricName(\"mse\").evaluate(newPrediction)\n",
    "print(f\"The MSE for the random forest regression model is {mse:0.2f}\")\n",
    "# R2\n",
    "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(newPrediction)\n",
    "print(f\"The R2 for the random forest regression model is {r2:0.2f}\")\n",
    "# MAE\n",
    "mae = regressionEvaluator.setMetricName(\"mae\").evaluate(newPrediction)\n",
    "print(f\"The MAE for the random forest regression model is {mae:0.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
